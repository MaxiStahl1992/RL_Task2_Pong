{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "from stable_baselines3 import PPO, A2C, DQN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.atari_wrappers import AtariWrapper\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "import numpy as np\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb3_models_info = [\n",
    "    # DQN Models\n",
    "    {\n",
    "        \"algorithm\": \"DQN\",\n",
    "        \"model_name\": \"dqn_model_10800\",\n",
    "        \"repo_id\": \"maxstahl/dqn_pongnoframskip_v4_sb3\",\n",
    "        \"filename\": \"dqn_PongNoFrameskip-v4_10800.zip\"\n",
    "    },\n",
    "    {\n",
    "        \"algorithm\": \"DQN\",\n",
    "        \"model_name\": \"dqn_model_21600\",\n",
    "        \"repo_id\": \"maxstahl/dqn_pongnoframskip_v4_sb3\",\n",
    "        \"filename\": \"dqn_PongNoFrameskip-v4_21600.zip\"\n",
    "    },\n",
    "    {\n",
    "        \"algorithm\": \"DQN\",\n",
    "        \"model_name\": \"dqn_model_32400\",\n",
    "        \"repo_id\": \"maxstahl/dqn_pongnoframskip_v4_sb3\",\n",
    "        \"filename\": \"dqn_PongNoFrameskip-v4_32400.zip\"\n",
    "    },\n",
    "    # A2C Models\n",
    "    {\n",
    "        \"algorithm\": \"A2C\",\n",
    "        \"model_name\": \"a2c_model_10800\",\n",
    "        \"repo_id\": \"maxstahl/a2c_pongnoframskip_v4_sb3\",\n",
    "        \"filename\": \"a2c_PongNoFrameskip-v4_10800.zip\"\n",
    "    },\n",
    "    {\n",
    "        \"algorithm\": \"A2C\",\n",
    "        \"model_name\": \"a2c_model_21600\",\n",
    "        \"repo_id\": \"maxstahl/a2c_pongnoframskip_v4_sb3\",\n",
    "        \"filename\": \"a2c_PongNoFrameskip-v4_21600.zip\"\n",
    "    },\n",
    "    {\n",
    "        \"algorithm\": \"A2C\",\n",
    "        \"model_name\": \"a2c_model_32400\",\n",
    "        \"repo_id\": \"maxstahl/a2c_pongnoframskip_v4_sb3\",\n",
    "        \"filename\": \"a2c_PongNoFrameskip-v4_32400.zip\"\n",
    "    },\n",
    "    # PPO Models\n",
    "    {\n",
    "        \"algorithm\": \"PPO\",\n",
    "        \"model_name\": \"ppo_model_10800\",\n",
    "        \"repo_id\": \"maxstahl/ppo_pongnoframskip_v4_sb3\",\n",
    "        \"filename\": \"ppo_PongNoFrameskip-v4_10800.zip\"\n",
    "    },\n",
    "    {\n",
    "        \"algorithm\": \"PPO\",\n",
    "        \"model_name\": \"ppo_model_21600\",\n",
    "        \"repo_id\": \"maxstahl/ppo_pongnoframskip_v4_sb3\",\n",
    "        \"filename\": \"ppo_PongNoFrameskip-v4_21600.zip\"\n",
    "    },\n",
    "    {\n",
    "        \"algorithm\": \"PPO\",\n",
    "        \"model_name\": \"ppo_model_32400\",\n",
    "        \"repo_id\": \"maxstahl/ppo_pongnoframskip_v4_sb3\",\n",
    "        \"filename\": \"ppo_PongNoFrameskip-v4_32400.zip\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: dqn_model_10800 (DQN)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stahlma/anaconda3/envs/gymnasium/lib/python3.10/site-packages/ipywidgets/widgets/widget.py:503: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "  self.comm = Comm(**args)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea963be29a274d42922f4a9fe6e6ed23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dqn_PongNoFrameskip-v4_10800.zip:   0%|          | 0.00/27.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: dqn_model_21600 (DQN)\n",
      "Loading model: dqn_model_32400 (DQN)\n",
      "Loading model: a2c_model_10800 (A2C)\n",
      "Loading model: a2c_model_21600 (A2C)\n",
      "Loading model: a2c_model_32400 (A2C)\n",
      "Loading model: ppo_model_10800 (PPO)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stahlma/anaconda3/envs/gymnasium/lib/python3.10/site-packages/ipywidgets/widgets/widget.py:503: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "  self.comm = Comm(**args)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70d3764cec1644548181b63016bb6b2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ppo_PongNoFrameskip-v4_10800.zip:   0%|          | 0.00/20.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: ppo_model_21600 (PPO)\n",
      "Loading model: ppo_model_32400 (PPO)\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store loaded models\n",
    "loaded_sb3_models = []\n",
    "\n",
    "# Iterate over each model info and load the models\n",
    "for model_info in sb3_models_info:\n",
    "    print(f\"Loading model: {model_info['model_name']} ({model_info['algorithm']})\")\n",
    "    model_path = hf_hub_download(\n",
    "        repo_id=model_info[\"repo_id\"],\n",
    "        filename=model_info[\"filename\"]\n",
    "    )\n",
    "    if model_info[\"algorithm\"] == \"DQN\":\n",
    "        model = DQN.load(model_path, device='cpu')  # Change 'cpu' to 'cuda' if using GPU\n",
    "    elif model_info[\"algorithm\"] == \"A2C\":\n",
    "        model = A2C.load(model_path, device='cpu')\n",
    "    elif model_info[\"algorithm\"] == \"PPO\":\n",
    "        model = PPO.load(model_path, device='cpu')\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported algorithm: {model_info['algorithm']}\")\n",
    "    \n",
    "    # Append the loaded model along with its info to the list\n",
    "    loaded_sb3_models.append({\n",
    "        \"algorithm\": model_info[\"algorithm\"],\n",
    "        \"model_name\": model_info[\"model_name\"],\n",
    "        \"model\": model\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluation Fuctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_eval_env(env_id, seed):\n",
    "    eval_env = gym.make(env_id, render_mode=\"rgb_array\")\n",
    "    eval_env = AtariWrapper(eval_env, clip_reward=False, terminal_on_life_loss=False)\n",
    "    eval_env = Monitor(eval_env)\n",
    "    eval_env.seed(seed)\n",
    "    eval_env.action_space.seed(seed)\n",
    "    return eval_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_save(model, env, num_episodes, save_path):\n",
    "    \"\"\"\n",
    "    Evaluate an SB3 model and save the metrics to a JSON file.\n",
    "\n",
    "    Args:\n",
    "        model (BaseAlgorithm): The SB3 model to evaluate.\n",
    "        env (VecEnv): The environment to evaluate on.\n",
    "        num_episodes (int): Number of episodes to evaluate.\n",
    "        save_path (str): Path to save the JSON metrics.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing per-episode rewards, mean reward, and std reward.\n",
    "    \"\"\"\n",
    "    # Initialize list to store rewards\n",
    "    total_rewards = []\n",
    "\n",
    "    for episode in range(1, num_episodes + 1):\n",
    "        obs = env.reset()[0]  # Reset and get the initial observation\n",
    "        done = False\n",
    "        episode_reward = 0\n",
    "\n",
    "        while not done:\n",
    "            # Predict action using the model\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            obs, reward, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "            episode_reward += reward\n",
    "\n",
    "        total_rewards.append(episode_reward)\n",
    "        print(f\"Episode {episode}: Reward = {episode_reward}\")\n",
    "\n",
    "    # Calculate mean and standard deviation\n",
    "    mean_reward = np.mean(total_rewards)\n",
    "    std_reward = np.std(total_rewards)\n",
    "\n",
    "    # Prepare metrics dictionary\n",
    "    metrics = {\n",
    "        'per_episode_rewards': total_rewards,\n",
    "        'mean_reward': mean_reward,\n",
    "        'std_reward': std_reward\n",
    "    }\n",
    "\n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "    # Save metrics to JSON\n",
    "    with open(save_path, 'w') as f:\n",
    "        json.dump(metrics, f, indent=4)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env_id = \"PongNoFrameskip-v4\"\n",
    "env_id = \"ALE/Pong-v5\"\n",
    "seed = 73\n",
    "\n",
    "# Create the environment\n",
    "env = make_eval_env(env_id=env_id, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating DQN Model: dqn_model_10800\n",
      "Episode 1: Reward = -21.0\n",
      "Episode 2: Reward = -20.0\n",
      "Episode 3: Reward = -20.0\n",
      "Episode 4: Reward = -20.0\n",
      "Episode 5: Reward = -18.0\n",
      "Episode 6: Reward = -21.0\n",
      "Episode 7: Reward = -21.0\n",
      "Episode 8: Reward = -19.0\n",
      "Episode 9: Reward = -19.0\n",
      "Episode 10: Reward = -21.0\n",
      "Saved metrics to ./metrics/sb3_eval/test/dqn_model_10800/metrics.json\n",
      "\n",
      "Evaluating DQN Model: dqn_model_21600\n",
      "Episode 1: Reward = -19.0\n",
      "Episode 2: Reward = -21.0\n",
      "Episode 3: Reward = -19.0\n",
      "Episode 4: Reward = -21.0\n",
      "Episode 5: Reward = -21.0\n",
      "Episode 6: Reward = -18.0\n",
      "Episode 7: Reward = -21.0\n",
      "Episode 8: Reward = -21.0\n",
      "Episode 9: Reward = -20.0\n",
      "Episode 10: Reward = -21.0\n",
      "Saved metrics to ./metrics/sb3_eval/test/dqn_model_21600/metrics.json\n",
      "\n",
      "Evaluating DQN Model: dqn_model_32400\n",
      "Episode 1: Reward = -21.0\n",
      "Episode 2: Reward = -21.0\n",
      "Episode 3: Reward = -21.0\n",
      "Episode 4: Reward = -21.0\n",
      "Episode 5: Reward = -20.0\n",
      "Episode 6: Reward = -20.0\n",
      "Episode 7: Reward = -21.0\n",
      "Episode 8: Reward = -21.0\n",
      "Episode 9: Reward = -21.0\n",
      "Episode 10: Reward = -20.0\n",
      "Saved metrics to ./metrics/sb3_eval/test/dqn_model_32400/metrics.json\n",
      "\n",
      "Evaluating A2C Model: a2c_model_10800\n",
      "Episode 1: Reward = -20.0\n",
      "Episode 2: Reward = -21.0\n",
      "Episode 3: Reward = -18.0\n",
      "Episode 4: Reward = -21.0\n",
      "Episode 5: Reward = -20.0\n",
      "Episode 6: Reward = -19.0\n",
      "Episode 7: Reward = -20.0\n",
      "Episode 8: Reward = -19.0\n",
      "Episode 9: Reward = -20.0\n",
      "Episode 10: Reward = -19.0\n",
      "Saved metrics to ./metrics/sb3_eval/test/a2c_model_10800/metrics.json\n",
      "\n",
      "Evaluating A2C Model: a2c_model_21600\n",
      "Episode 1: Reward = -20.0\n",
      "Episode 2: Reward = -19.0\n",
      "Episode 3: Reward = -20.0\n",
      "Episode 4: Reward = -20.0\n",
      "Episode 5: Reward = -19.0\n",
      "Episode 6: Reward = -18.0\n",
      "Episode 7: Reward = -21.0\n",
      "Episode 8: Reward = -20.0\n",
      "Episode 9: Reward = -17.0\n",
      "Episode 10: Reward = -20.0\n",
      "Saved metrics to ./metrics/sb3_eval/test/a2c_model_21600/metrics.json\n",
      "\n",
      "Evaluating A2C Model: a2c_model_32400\n",
      "Episode 1: Reward = -21.0\n",
      "Episode 2: Reward = -21.0\n",
      "Episode 3: Reward = -21.0\n",
      "Episode 4: Reward = -21.0\n",
      "Episode 5: Reward = -21.0\n",
      "Episode 6: Reward = -21.0\n",
      "Episode 7: Reward = -21.0\n",
      "Episode 8: Reward = -21.0\n",
      "Episode 9: Reward = -21.0\n",
      "Episode 10: Reward = -21.0\n",
      "Saved metrics to ./metrics/sb3_eval/test/a2c_model_32400/metrics.json\n",
      "\n",
      "Evaluating PPO Model: ppo_model_10800\n",
      "Episode 1: Reward = -21.0\n",
      "Episode 2: Reward = -21.0\n",
      "Episode 3: Reward = -21.0\n",
      "Episode 4: Reward = -20.0\n",
      "Episode 5: Reward = -20.0\n",
      "Episode 6: Reward = -21.0\n",
      "Episode 7: Reward = -21.0\n",
      "Episode 8: Reward = -20.0\n",
      "Episode 9: Reward = -20.0\n",
      "Episode 10: Reward = -20.0\n",
      "Saved metrics to ./metrics/sb3_eval/test/ppo_model_10800/metrics.json\n",
      "\n",
      "Evaluating PPO Model: ppo_model_21600\n",
      "Episode 1: Reward = -21.0\n",
      "Episode 2: Reward = -21.0\n",
      "Episode 3: Reward = -21.0\n",
      "Episode 4: Reward = -21.0\n",
      "Episode 5: Reward = -21.0\n",
      "Episode 6: Reward = -21.0\n",
      "Episode 7: Reward = -20.0\n",
      "Episode 8: Reward = -21.0\n",
      "Episode 9: Reward = -21.0\n",
      "Episode 10: Reward = -21.0\n",
      "Saved metrics to ./metrics/sb3_eval/test/ppo_model_21600/metrics.json\n",
      "\n",
      "Evaluating PPO Model: ppo_model_32400\n",
      "Episode 1: Reward = -21.0\n",
      "Episode 2: Reward = -21.0\n",
      "Episode 3: Reward = -21.0\n",
      "Episode 4: Reward = -21.0\n",
      "Episode 5: Reward = -21.0\n",
      "Episode 6: Reward = -21.0\n",
      "Episode 7: Reward = -21.0\n",
      "Episode 8: Reward = -21.0\n",
      "Episode 9: Reward = -21.0\n",
      "Episode 10: Reward = -21.0\n",
      "Saved metrics to ./metrics/sb3_eval/test/ppo_model_32400/metrics.json\n"
     ]
    }
   ],
   "source": [
    "# Define the number of evaluation episodes\n",
    "NUM_EPISODES = 10\n",
    "\n",
    "# Define the base directory for saving metrics\n",
    "base_metrics_dir = './metrics/sb3_eval/test'\n",
    "\n",
    "# Initialize a list to store evaluation results for the summary table\n",
    "evaluation_results = []\n",
    "\n",
    "# Iterate through each loaded SB3 model and evaluate\n",
    "for sb3_model_info in loaded_sb3_models:\n",
    "    algorithm = sb3_model_info[\"algorithm\"]\n",
    "    model_name = sb3_model_info[\"model_name\"]\n",
    "    model = sb3_model_info[\"model\"]\n",
    "    \n",
    "    print(f\"\\nEvaluating {algorithm} Model: {model_name}\")\n",
    "    \n",
    "    # Define the path to save metrics\n",
    "    model_metrics_dir = os.path.join(base_metrics_dir, model_name)\n",
    "    metrics_save_path = os.path.join(model_metrics_dir, 'metrics.json')\n",
    "    \n",
    "    # Evaluate the model and save metrics\n",
    "    metrics = evaluate_and_save(\n",
    "        model=model,\n",
    "        env=env,\n",
    "        num_episodes=NUM_EPISODES,\n",
    "        save_path=metrics_save_path\n",
    "    )\n",
    "    \n",
    "    print(f\"Saved metrics to {metrics_save_path}\")\n",
    "    \n",
    "    # Append results to the list for the summary table\n",
    "    evaluation_results.append({\n",
    "        \"Algorithm\": algorithm,\n",
    "        \"Model Name\": model_name,\n",
    "        \"Mean Reward\": metrics[\"mean_reward\"],\n",
    "        \"Std Reward\": metrics[\"std_reward\"]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of SB3 Models Evaluation:\n",
      "  Algorithm       Model Name  Mean Reward  Std Reward\n",
      "0       DQN  dqn_model_10800        -20.0    1.000000\n",
      "1       DQN  dqn_model_21600        -20.2    1.077033\n",
      "2       DQN  dqn_model_32400        -20.7    0.458258\n",
      "3       A2C  a2c_model_10800        -19.7    0.900000\n",
      "4       A2C  a2c_model_21600        -19.4    1.113553\n",
      "5       A2C  a2c_model_32400        -21.0    0.000000\n",
      "6       PPO  ppo_model_10800        -20.5    0.500000\n",
      "7       PPO  ppo_model_21600        -20.9    0.300000\n",
      "8       PPO  ppo_model_32400        -21.0    0.000000\n"
     ]
    }
   ],
   "source": [
    "# Create a Pandas DataFrame from the evaluation results\n",
    "results_df = pd.DataFrame(evaluation_results)\n",
    "\n",
    "# Display the summary table\n",
    "print(\"\\nSummary of SB3 Models Evaluation:\")\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gymnasium",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
